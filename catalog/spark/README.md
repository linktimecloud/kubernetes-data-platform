### 1. 介绍

Apache Spark 是用于大规模数据处理的统一分析引擎。 它提供了 Java、Scala、Python 和 R 的高级 API，以及支持通用执行图的优化引擎。 它还支持一组丰富的高级工具，包括用于 SQL 和结构化数据处理的 Spark SQL、用于 pandas 工作负载的 Spark 上的 pandas API、用于机器学习的 MLlib、用于图形处理的 GraphX 以及用于增量计算和流处理的 Structured Streaming。

### 2. 产品能力

#### 批/流式数据

统一处理批量数据和实时流数据，使用您喜爱的语言:Python, SQL, Scala, Java或R。

#### SQL分析

执行快速、分布式的ANSI SQL查询，用于仪表板和临时报告，且运行速度比大多数数据仓库快。

#### 大规模数据科学

对PB级数据执行探索性数据分析（EDA），而无需进行采用降维技术

#### 机器学习

在笔记本电脑上训练机器学习算法，并使用相同的代码扩展到数千台机器的容错集群。

### 3. 应用场景

Apache Spark 是一种用于大数据工作负载的通用型分布式处理系统。它已经被部署到每种大数据用例类型中，用来侦测模式并提供实时见解。

#### 金融服务

Spark 被用于银行业务，来预测客户流失与推荐新的金融产品。在投资银行业务中，Spark 被用来分析股价，并预测未来的走势。

#### 医疗保健

Spark 被用于构建全方位的病人照护，在每次与病人的互动中为第一线医疗人员提供数据。Spark 还可被用来预测/推荐病人治疗方案。

#### 制造

Spark 被用来建议在什么时候进行预防性维护，从而避免联网设备停机。

#### 零售

Spark 通过其个性化的服务和产品来吸引和留住客户。
